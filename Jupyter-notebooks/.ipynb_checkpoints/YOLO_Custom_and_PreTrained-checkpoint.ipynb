{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb98b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf51df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../Assets/images/predict-2.jpeg'\n",
    "video_path = '../Assets/videos/vehicles1.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f36fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFeatures(frame, net, ln, Labels,bicycleIndx=0, carIndx=0, motorbikeIndx=0, busIndx=0, truckIndx=0):\n",
    "    \n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    #We'll store out predicitons with it's details such as confidence, bounding box points in results\n",
    "    results=[]\n",
    "    \n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob=cv2.dnn.blobFromImage(frame, 1/255.0,(416,416), swapRB=True, crop=False)\n",
    "    \n",
    "    \n",
    "    #Giving the blob as input to our model to process this frame\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    #Getting the output of our Model which contains predictions\n",
    "    layerOutputs=net.forward(ln)\n",
    "    end = time.time()\n",
    "    \n",
    "    #We'll Stores the bounding box co-ordinates, confidences, ID which corresponds to object it is in these for our predictions\n",
    "    boxes=[]\n",
    "    confidences=[]\n",
    "    classIDs=[]\n",
    "    classname = []\n",
    "    #Iterate though our outputs and each detection in each output\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            #Extract Confidence for each detection and it's ID for item it corresponds to\n",
    "            scores=detection[5:]\n",
    "            classID=np.argmax(scores)\n",
    "            confidence=scores[classID]\n",
    "            \n",
    "            #We just want Bicycles, Cars, Bikes, Trucks and Buses to be detected\n",
    "            if ((classID==bicycleIndx or classID==carIndx or classID==motorbikeIndx or classID==busIndx or classID==truckIndx) and confidence>0.5):\n",
    "                #Get the boundary box co-ordinates for our Detectection\n",
    "                box=detection[0:4]*np.array([W,H,W,H])\n",
    "                (centerX, centerY, width, height)=box.astype('int')\n",
    "                x=int(centerX-(width/2))\n",
    "                y=int(centerY-(height/2))\n",
    "                \n",
    "                #Save these co-ordinates, confidence, ID of item number in the lists we initialized\n",
    "                boxes.append([x,y,int(width),int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                classname.append(Labels[classID])\n",
    "                \n",
    "    #Applying Non-Max Suppression to remove extra Bounding Boxes\n",
    "    indxs=cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.5)\n",
    "    \n",
    "#     boxes = [boxes[i] for i in indxs]\n",
    "#     classname = [classname[i] for i in indxs]\n",
    "#     confidences = [confidences[i] for i in indxs]\n",
    "#     classIDs = [classIDs[i] for i in indxs]\n",
    "    \n",
    "    \n",
    "    #Storing Final Detection's features in results\n",
    "    if len(indxs)>0:\n",
    "        for i in indxs.flatten():\n",
    "            (x,y)=(boxes[i][0], boxes[i][1])\n",
    "            (w,h)=(boxes[i][2],boxes[i][3])\n",
    "            r=(confidences[i], (x,y,x+w,y+h),classIDs[i],classname[i])\n",
    "            results.append(r)\n",
    "#     print(results)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    cv2.waitKey(0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b172f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vehicle_count(boxes, class_names,list_of_vehicles):\n",
    "    \n",
    "    total_vehicle_count = 0 # total vechiles present in the image\n",
    "    dict_vehicle_count = {} # dictionary with count of each distinct vehicles detected\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "\n",
    "            class_name = class_names[i]\n",
    "       \n",
    "            if(class_name in list_of_vehicles):\n",
    "                total_vehicle_count += 1\n",
    "                dict_vehicle_count[class_name] = dict_vehicle_count.get(class_name,0) + 1\n",
    "\n",
    "    return total_vehicle_count, dict_vehicle_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b2cdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customYolo(frame):\n",
    "    \n",
    "    \n",
    "    # setting the paths\n",
    "    coco_names_path = '../Assets/yolo-coco/custom/classes.names'\n",
    "    weightsPath = '../Assets/yolo-coco/custom/Training-2/yolov3_custom_last_6000.weights'\n",
    "    configPath = '../Assets/yolo-coco/custom/yolov3_custom.cfg'\n",
    "    \n",
    "    \n",
    "    # load the COCO class labels our YOLO model was trained on\n",
    "    Labels = []\n",
    "    with open(coco_names_path,'r',encoding='utf8') as f:\n",
    "        Labels = [line.strip() for line in f.readlines()]\n",
    "#     print(Labels)\n",
    "    \n",
    "    \n",
    "    # initialize a list of colors to represent each possible class label\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(Labels), 3),dtype=\"uint8\")\n",
    "    \n",
    "    \n",
    "    # load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "    # and determine only the *output* layer names that we need from YOLO\n",
    "    net = cv2.dnn.readNetFromDarknet(configPath,weightsPath)\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    \n",
    "#     list_of_vehicles = ['car', 'truck', 'bus', 'motorbike', 'bicycle']\n",
    "    list_of_vehicles = ['car', 'truck', 'bus', 'motorbike', 'bicycle', 'ambulance', 'fire engine','auto rickshaw']\n",
    "   \n",
    "    # if the frame dimensions are empty, grab them\n",
    "#     if W is None or H is None:\n",
    "#     print(frame.shape)\n",
    "    (H, W) = frame.shape[:2]\n",
    "    \n",
    "#     print(frame.shape)\n",
    "#     cv2.imshow(\"frame\",frame)\n",
    "#     cv2.waitKey(0)\n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(output_layers)\n",
    "    end = time.time()\n",
    "\n",
    "    # initialize our lists of detected bounding boxes, confidences,\n",
    "    # and class IDs, respectively\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    classname = []\n",
    "#     print(layerOutputs)\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability)\n",
    "            # of the current object detection\n",
    "          \n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            if confidence > 0.5:\n",
    "                # scale the bounding box coordinates back relative to\n",
    "                # the size of the image, keeping in mind that YOLO\n",
    "                # actually returns the center (x, y)-coordinates of\n",
    "                # the bounding box followed by the boxes' width and\n",
    "                # height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top\n",
    "                # and and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates,\n",
    "                # confidences, and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                classname.append(Labels[classID])\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.5)\n",
    "    results = []\n",
    "    if len(idxs)>0:\n",
    "        for i in idxs.flatten():\n",
    "            (x,y)=(boxes[i][0], boxes[i][1])\n",
    "            (w,h)=(boxes[i][2],boxes[i][3])\n",
    "            r=(confidences[i], (x,y,x+w,y+h),classIDs[i],classname[i])\n",
    "            results.append(r)\n",
    "\n",
    "    boxes = [boxes[i] for i in idxs]\n",
    "    classname = [classname[i] for i in idxs]\n",
    "\n",
    "    total_vehicles, each_vehicle = get_vehicle_count(boxes, classname,list_of_vehicles)\n",
    "\n",
    "\n",
    "    return each_vehicle,results\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67ff9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTrainedYolo():\n",
    "    \n",
    "    # setting the paths\n",
    "    coco_names_path = '../Assets/yolo-coco/coco.names'\n",
    "    weightsPath = '../Assets/yolo-coco/yolov3.weights'\n",
    "    configPath = '../Assets/yolo-coco/yolov3.cfg'    \n",
    "    \n",
    "    \n",
    "    # load the COCO class labels our YOLO model was trained on\n",
    "    Labels = []\n",
    "    with open(coco_names_path,'r',encoding='utf8') as f:\n",
    "        Labels = [line.strip() for line in f.readlines()]\n",
    "#     print(Labels)\n",
    "    \n",
    "    \n",
    "    list_of_vehicles = ['car', 'truck', 'bus', 'motorbike', 'bicycle', 'ambulance', 'fire engine','auto rickshaw']\n",
    "   \n",
    "    # initialize a list of colors to represent each possible class label\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(list_of_vehicles), 3),dtype=\"uint8\")\n",
    "    \n",
    "    \n",
    "    # load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "    # and determine only the *output* layer names that we need from YOLO\n",
    "    net = cv2.dnn.readNetFromDarknet(configPath,weightsPath)\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    # initialize the video stream, pointer to output video file, and\n",
    "    # frame dimensions\n",
    "    vs = cv2.VideoCapture(image_path)\n",
    "    writer = None\n",
    "    (W, H) = (None, None)\n",
    "    fps=vs.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "#     # try to determine the total number of frames in the video file\n",
    "#     try:\n",
    "#         prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "#             else cv2.CAP_PROP_FRAME_COUNT\n",
    "#         total = int(vs.get(prop))\n",
    "#         print(\"[INFO] {} total frames in video\".format(total))\n",
    "\n",
    "#     # an error occurred while trying to determine the total\n",
    "#     # number of frames in the video file\n",
    "#     except:\n",
    "#         print(\"[INFO] could not determine # of frames in video\")\n",
    "#         print(\"[INFO] no approx. completion time can be provided\")\n",
    "#         total = -1\n",
    "    \n",
    "#     tempPath='../Assets/images/EmergencyVehicleClassificationFastAI/1.jpg'\n",
    "    \n",
    "    while True:\n",
    "        #Reading frame from video\n",
    "        (grabbed, frame) = vs.read()\n",
    "\n",
    "        # if the frame was not grabbed, then we have reached the end\n",
    "        # of the stream\n",
    "        if not grabbed:\n",
    "            break\n",
    "        \n",
    "        \n",
    "#         frame = imutils.resize(frame, width=400)\n",
    "        \n",
    "        #Extracting individual bounding boxes\n",
    "        results = detectFeatures(frame, net, output_layers,Labels,bicycleIndx=Labels.index('bicycle'), carIndx=Labels.index('car'), motorbikeIndx=Labels.index('motorbike'), busIndx=Labels.index('bus'), truckIndx=Labels.index('truck'))\n",
    "        #Setting Number of Vehicles initially 0\n",
    "        vehicles=0\n",
    "        emergency = 0\n",
    "        urgent=False\n",
    "        active=False\n",
    "        dict_vehicles = {}\n",
    "        \n",
    "        #Iterating through our results in Current frame\n",
    "        if(results):\n",
    "            # results list is not empty\n",
    "            for (i,(prob, bbox, classID, name)) in enumerate(results):\n",
    "\n",
    "                #Getting co-ordinates our current detection, and adding to corresponding Detection we got\n",
    "                real_name = name\n",
    "                (startX, startY, endX, endY) = bbox\n",
    "                if name=='car' or name=='bus' or name=='truck':\n",
    "\n",
    "                    vehicle=frame[startY:endY, startX:endX]\n",
    "                    \n",
    "                    (H,W) = vehicle.shape[:2]\n",
    "                    if H==0 or W==0:\n",
    "                        continue\n",
    "                        \n",
    "                    each_vehicle,_ = customYolo(vehicle)\n",
    "\n",
    "\n",
    "                    if(each_vehicle):\n",
    "                        for key,value in each_vehicle.items():\n",
    "\n",
    "                            dict_vehicles[key] = dict_vehicles.get(key,0) + value\n",
    "\n",
    "                            if((key=='ambulance' or key=='fire engine') and active==True):\n",
    "                                urgent = True\n",
    "\n",
    "                            real_name = key\n",
    "                    else:\n",
    "                        dict_vehicles[name] = dict_vehicles.get(name,0) + 1\n",
    "\n",
    "                elif name=='bicycle' or name=='motorbike':\n",
    "                    dict_vehicles[name] = dict_vehicles.get(name,0) + 1\n",
    "\n",
    "\n",
    "                #Plotting rectangle around the detection and displaying what it is                                                     \n",
    "                color = [int(c) for c in COLORS[list_of_vehicles.index(real_name)]]\n",
    "                cv2.rectangle(frame, (startX,startY),(endX,endY),color,2)\n",
    "                cv2.putText(frame, real_name, (startX,startY-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            _,res = customYolo(frame)\n",
    "            \n",
    "            (H,W) = frame.shape[:2]\n",
    "            \n",
    "            if H==0 or W==0:\n",
    "                pass\n",
    "            else:\n",
    "                for (i,(prob, bbox, classID, name)) in enumerate(res):\n",
    "\n",
    "                    (startX, startY, endX, endY) = bbox\n",
    "                    dict_vehicles[name] = dict_vehicles.get(name,0) + 1  \n",
    "                    #Plotting rectangle around the detection and displaying what it is                                                     \n",
    "                    color = [int(c) for c in COLORS[list_of_vehicles.index(name)]]\n",
    "                    cv2.rectangle(frame, (startX,startY),(endX,endY),color,2)\n",
    "                    cv2.putText(frame, name, (startX,startY-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "        \n",
    "        \n",
    "        print(dict_vehicles)\n",
    "        cv2.imshow('Frame',frame)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        if writer is None:\n",
    "            fourcc=cv2.VideoWriter_fourcc(*'MJPG')\n",
    "            writer=cv2.VideoWriter('../Assets/images/predictedResult.jpeg', fourcc, 30, (frame.shape[1],frame.shape[0]), True)\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "        \n",
    "    writer.release()\n",
    "    vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e80a2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'car': 11, 'auto rickshaw': 11, 'bus': 1, 'ambulance': 1, 'bicycle': 13, 'motorbike': 9}\n"
     ]
    }
   ],
   "source": [
    "preTrainedYolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7fb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbbea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8526f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d48c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3bcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25f8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ea425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569d74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4797cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cb510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7686df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61989c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
